{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n",
    "***\n",
    "### Machine learning: The problem setting\n",
    "A learning problem reviews a set of n tests of data and then attempts to predict unknown data as to the name Machine Learning. It learns as it goes and gets smarter everytime it runs a differnt peice of code.\n",
    "If each test is more than a single integer such as an array of numbers it has multiple attributes.\n",
    "- Supervissed learning: is when we have data with additional attributes and we want to predict them.\n",
    " - Classification: is a problem of id'ing which list an study belongs to. One way to think of this is having a discrte way of way of supervised learning and one only has a certain amount of categories, and for each N sample that is given has to put them in the right place.\n",
    "  - Regression: if the output is the same then we have run into regression. An example of this is when you try to predict something it wont give the right answer or give the same answer everytime.\n",
    "- Unsupervised learning: the training data that is used is a set of input vectors and having no similar target values. The aim is to have some problems and have them find the same examples in the dataset. This is called clustering.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an example dataset.\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/tutorial/index.html) comes with some standard datasets for example iris and digits for classification and the [diabetes dataset](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Dataset is an object that acts in a dictonary-like way and has some data and metadata. This is all stored in the .data member, which are two different arrays called samples and features. With using the supervised problem response vars are stored in the .target memeber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**digits.data** gives you digits samples and **digits.target** gives you true values of the dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the data is shown is always in a 2D array. The shape of the array is (samples,features). The inital data mey take a different shape but in the case of the way the digits each inital sample image shape is an 8*8 array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Learning and predicting\n",
    "Using the digits dataset, There is samples of each of the 10 possible classes on where we can fit an **estimator**(which is a rule for calculating an estimate of given quantity based on observed data) to predict unseen samples.\n",
    "\n",
    "But in scikit-learn, an estimator for grouping is a Python object that implements the methods fit() and predict()\n",
    "\n",
    "An example of the use of estimator is sklearn.svm.SVC, which applies support for vector classification. The estimators constructor takes the models parameters as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**clf** (classifier) estimator instance is the first thing added to the model and must learn from it. \n",
    "This is done by passing it to the fit method. With the training set, we use all but the last image in the dataset which we use to do our predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, gamma=0.001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(digits.data[:-1], digits.target[:-1])\n",
    "svm.SVC(C=100.0, gamma=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict new values, in this instance we use the last image to do the work for use using digits.data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(digits.data[-1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators follow rules that make their behavior more predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Type casting\n",
    "- Unless told otherwise, input will be cast to foat64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing needed libraries\n",
    "import numpy as np\n",
    "from sklearn import random_projection\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.rand(10, 2000)\n",
    "X = np.array(X, dtype='float32')\n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippent of code above shows that dtype is a float32 but is cast to a float64. Regression targets are cast to float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing needed libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#setting variables.\n",
    "iris = datasets.load_iris()\n",
    "clf = SVC()\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "list(clf.predict(iris.data[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(iris.data, iris.target_names[iris.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['setosa', 'setosa', 'setosa']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clf.predict(iris.data[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - with using **fit()** it will return an integer array, But with using **predict()** you will get back a string array. This shows the different uses between the two and in what way to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Refitting and updating parameters.\n",
    "\n",
    "- In the code below we will be using **set_params()** method instead of using fit() multiple times as it would just overrite what is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# setting vars\n",
    "X,y = load_iris(return_X_y=True)\n",
    "\n",
    "clf = SVC()\n",
    "clf.set_params(kernel='linear').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(kernel='rbf').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the snippets above rbf kernel is change to linear from using **SVC.set_params** after it has been set in the constructor and is then changed back to rbf to refit the esitmator so it can make another prediction but it comes back with he same answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Multiclass vs. multilabel fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With using multiclass classifiers, learning and predictions is all down to how the format of the way the data is fit. Such as one vs all, one vs one and one vs the rest. These estimators are meta estimators, they need a base estimator to use in the constructor. For example we can use estimators to turn binary classifiers to a multiclass classifier.\n",
    "\n",
    "- With the code below you have OneVsRest. This consists of fitting one classifier per class. More about this can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 1, 7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "x = [[6,10], [4,7], [3,8], [5,10], [11,4]]\n",
    "y = [2,4,6,1,7]\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "classif.fit(x,y).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- above you can see that the classifier is fit into a noramal array of multiclass labels using the predict() method and shows similar predictions. We can also use a 2d array to fit the data into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = LabelBinarizer().fit_transform(y)\n",
    "classif.fit(x,y).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the above code you can see the the classifier if fit() to 2d array in the shape of **y** by using [LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier). Using LabelBinarizer is a group of regression and binary classification algorithms. Such as fit(), fit_transform() and get_params([]) this one in particular gets the parameters for a certain estimator you pass in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[2,6], [4,7], [5,2], [1,3], [6,3]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "classif.fit(x,y).predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the code above the classifier is fit onto instances that are assigned multiple labels. MultiLabelBinarizer is used on the 2d array of multilabels to fit on. Predict() returns a 2d array that has predicted labels for each instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
